{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de filtro colaborativo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tomas/workspace/uba/sr/sr-tpfinal-gh-web\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "THIS_FOLDER = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "print(THIS_FOLDER)\n",
    "\n",
    "# tables\n",
    "interacciones = 'interactions'\n",
    "items = 'repositories'\n",
    "users = 'users'\n",
    "\n",
    "# datasets to dfs\n",
    "con = sqlite3.connect(os.path.join(THIS_FOLDER, \"data/data.db\"))\n",
    "df_int = pd.read_sql_query(f\"SELECT * FROM {interacciones}\", con)\n",
    "df_items = pd.read_sql_query(f\"SELECT * FROM {items}\", con)\n",
    "df_users = pd.read_sql_query(f\"SELECT * FROM {users}\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dummies(data, column, sep=\";\", remove_original_column=False):\n",
    "    data_dummies = data[column].str.get_dummies(sep=sep)\n",
    "    data_with_dummies = pd.concat([data, data_dummies], axis=1)\n",
    "    if remove_original_column:\n",
    "        data_with_dummies = data_with_dummies.drop(columns=[column], axis=1)\n",
    "    return data_with_dummies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise\n",
    "\n",
    "Enfoque de recomendación con surprise no es posible dado que no se enfoca en recomendaciones binarias\n",
    "\n",
    "ver: https://github.com/NicolasHug/Surprise/issues/412"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implicit\n",
    "\n",
    "Libreria enfocada en recomendación binaria e implicita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "from scipy.sparse import coo_matrix \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_int = df_int.drop(columns=[\"index\", \"date\"])#.isnull().sum()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#list_null_repos = list(df_int[df_int[\"repository\"].isnull()].index)\n",
    "#print(df_int.shape)\n",
    "#print(df_int.dropna().shape)\n",
    "# Eliminar ese usuario e interacción\n",
    "df_int.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfint = df_int.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repository    0\n",
       "user          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfint.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfint.drop(columns=[\"index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfint[\"users\"] = dfint.user.astype(\"category\")#.unique()\n",
    "dfint[\"repos\"] = dfint.repository.astype(\"category\")#.unique()\n",
    "\n",
    "stars = coo_matrix((np.ones(dfint.shape[0]),\n",
    "                   (dfint['repos'].cat.codes.copy(),\n",
    "                    dfint['users'].cat.codes.copy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import bm25_weight\n",
    "from implicit.als import AlternatingLeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12955x298 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 22025 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stars_bm25 = bm25_weight(stars)\n",
    "stars_by_users = stars_bm25.T.tocsr()\n",
    "stars_by_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomas/workspace/uba/sr/sr-tpfinal-gh-web/.venv/lib/python3.10/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 12 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ef168878524483a630382cb0b27e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AlternatingLeastSquares(factors=64, regularization=0.05, alpha=2.0)\n",
    "model.fit(stars_by_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make recomendation\n",
    "userid = 'fly51fly'\n",
    "codeid = dfint['users'].cat.categories.get_loc(userid)\n",
    "#items_ids, items_scores = model.recommend(codeid, stars_by_users[codeid], N=10, filter_already_liked_items=False)\n",
    "items_ids, items_scores = model.recommend(codeid, stars_by_users[codeid], N=10, filter_already_liked_items=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repos</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>py-why/dowhy</td>\n",
       "      <td>0.513297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pyro-ppl/pyro</td>\n",
       "      <td>0.496485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>banditml/banditml</td>\n",
       "      <td>0.466755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>planetlabs/planet-client-python</td>\n",
       "      <td>0.447452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>huggingface/neuralcoref</td>\n",
       "      <td>0.430030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chainer/chainer</td>\n",
       "      <td>0.399927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mwydmuch/napkinXC</td>\n",
       "      <td>0.388848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lorismichel/drf</td>\n",
       "      <td>0.385448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IDSIA/sacred</td>\n",
       "      <td>0.381600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pycaret/pycaret</td>\n",
       "      <td>0.364547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             repos    scores\n",
       "0                     py-why/dowhy  0.513297\n",
       "1                    pyro-ppl/pyro  0.496485\n",
       "2                banditml/banditml  0.466755\n",
       "3  planetlabs/planet-client-python  0.447452\n",
       "4          huggingface/neuralcoref  0.430030\n",
       "5                  chainer/chainer  0.399927\n",
       "6                mwydmuch/napkinXC  0.388848\n",
       "7                  lorismichel/drf  0.385448\n",
       "8                     IDSIA/sacred  0.381600\n",
       "9                  pycaret/pycaret  0.364547"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"repos\": dfint['repos'].cat.categories[items_ids], \"scores\": items_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repos</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pytorch/pytorch</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pyro-ppl/pyro</td>\n",
       "      <td>0.425628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/wuffs</td>\n",
       "      <td>0.261818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iterative/dvc</td>\n",
       "      <td>0.244086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TeamHypersomnia/Hypersomnia</td>\n",
       "      <td>0.238672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kornia/kornia</td>\n",
       "      <td>0.230670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ray-project/ray</td>\n",
       "      <td>0.208496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rushter/MLAlgorithms</td>\n",
       "      <td>0.207611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>huggingface/neuralcoref</td>\n",
       "      <td>0.203042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rasbt/deep-learning-book</td>\n",
       "      <td>0.202782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         repos    scores\n",
       "0              pytorch/pytorch  1.000000\n",
       "1                pyro-ppl/pyro  0.425628\n",
       "2                 google/wuffs  0.261818\n",
       "3                iterative/dvc  0.244086\n",
       "4  TeamHypersomnia/Hypersomnia  0.238672\n",
       "5                kornia/kornia  0.230670\n",
       "6              ray-project/ray  0.208496\n",
       "7         rushter/MLAlgorithms  0.207611\n",
       "8      huggingface/neuralcoref  0.203042\n",
       "9     rasbt/deep-learning-book  0.202782"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar items\n",
    "repoid = 'pytorch/pytorch'\n",
    "coderepoid = dfint['repos'].cat.categories.get_loc(repoid)\n",
    "\n",
    "similar_items_ids, similar_items_scores = model.similar_items(coderepoid)\n",
    "pd.DataFrame({\"repos\": dfint['repos'].cat.categories[similar_items_ids], \"scores\": similar_items_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fly51fly</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nikitavoloboev</td>\n",
       "      <td>0.555298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oudommeas</td>\n",
       "      <td>0.528794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hardikudeshi</td>\n",
       "      <td>0.501235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>romanofficial</td>\n",
       "      <td>0.496216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nikolay</td>\n",
       "      <td>0.480198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xuanhan863</td>\n",
       "      <td>0.459712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>usmanakram232</td>\n",
       "      <td>0.458704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pushpendrapratap</td>\n",
       "      <td>0.454848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>julianxhokaxhiu</td>\n",
       "      <td>0.454445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              users    scores\n",
       "0          fly51fly  1.000000\n",
       "1    nikitavoloboev  0.555298\n",
       "2         oudommeas  0.528794\n",
       "3      hardikudeshi  0.501235\n",
       "4     romanofficial  0.496216\n",
       "5           nikolay  0.480198\n",
       "6        xuanhan863  0.459712\n",
       "7     usmanakram232  0.458704\n",
       "8  pushpendrapratap  0.454848\n",
       "9   julianxhokaxhiu  0.454445"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar users\n",
    "userid = 'fly51fly'\n",
    "codeuserid = dfint['users'].cat.categories.get_loc(userid)\n",
    "\n",
    "similar_users_ids, similar_users_scores = model.similar_users(codeuserid)\n",
    "pd.DataFrame({\"users\": dfint['users'].cat.categories[similar_users_ids], \"scores\": similar_users_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 repository           user\n",
      "0     tensorflow/tensorflow           mrry\n",
      "1     tensorflow/tensorflow         danbri\n",
      "2     tensorflow/tensorflow          rockt\n",
      "3     tensorflow/tensorflow  petro-rudenko\n",
      "4  huggingface/transformers         kashif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22025, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_int.head())\n",
    "df_int.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightfm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightfm as lfm\n",
    "from lightfm import data, cross_validation, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset de LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12955, 298)\n"
     ]
    }
   ],
   "source": [
    "# genero la codificación de los datasets\n",
    "ds = lfm.data.Dataset()\n",
    "ds.fit(users=df_int.user.unique(), items=df_int.repository.unique())\n",
    "print(ds.interactions_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construyo las interacciones\n",
    "(lfm_interactions, lfm_weights) = ds.build_interactions(df_int[[\"user\", \"repository\"]].itertuples(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lfm_train, lfm_test) = lfm.cross_validation.random_train_test_split(lfm_interactions, test_percentage=0.2, random_state=42)\n",
    "# no aplica porque son likes\n",
    "#(lfm_train_w, lfm_test_w) = lfm.cross_validation.random_train_test_split(lfm_weights, test_percentage=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f9408f0f490>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lfm.LightFM(no_components=10, k=5, n=10, learning_schedule='adagrad', loss='logistic', learning_rate=0.05, rho=0.95, epsilon=1e-06, item_alpha=0.0, user_alpha=0.0, max_sampled=10, random_state=None)\n",
    "model.fit(lfm_train,\n",
    "          #sample_weight=lfm_train_w #no aplica porque son likes\n",
    "          epochs=64,\n",
    "          num_threads=8,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluación del modelo base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027499322\n",
      "0.020668117\n"
     ]
    }
   ],
   "source": [
    "#lfm.evaluation.precision_at_k(model, test_interactions=lfm_test, train_interactions=lfm_train, k=10, preserve_rows=False, num_threads=8, check_intersections=True)\n",
    "train_precision = lfm.evaluation.precision_at_k(model, lfm_train, k=10, preserve_rows=False, num_threads=8, check_intersections=True)\n",
    "test_precision = lfm.evaluation.precision_at_k(model, lfm_test, k=10, preserve_rows=False, num_threads=8, check_intersections=True)\n",
    "\n",
    "print(train_precision.mean())\n",
    "print(test_precision.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1023916568194092\n",
      "0.15474207426950504\n"
     ]
    }
   ],
   "source": [
    "train_recall = lfm.evaluation.recall_at_k(model, lfm_train, k=10, preserve_rows=False, num_threads=8, check_intersections=True)\n",
    "test_recall = lfm.evaluation.recall_at_k(model, lfm_test, k=10, preserve_rows=False, num_threads=8, check_intersections=True)\n",
    "\n",
    "print(train_recall.mean())\n",
    "print(test_recall.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item features\n",
    "\n",
    "Se agregan features de los items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(';'.join([i for i in df_items[\"topics\"].values.tolist() if i is not None]).split(';'))\n",
    "#len(set(';'.join([i for i in df_items[\"topics\"].values.tolist() if i is not None]).split(';')))\n",
    "item_features = list(set(';'.join([i for i in df_items[\"language\"].values.tolist() if i is not None]).split(';'))) \\\n",
    "                + list(set(';'.join([i for i in df_items[\"topics\"].values.tolist() if i is not None]).split(';'))) \\\n",
    "                + list(df_items.forks.unique()) \\\n",
    "                + list(df_items.stars.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12955, 298)\n"
     ]
    }
   ],
   "source": [
    "ds_item_features = lfm.data.Dataset()\n",
    "ds_item_features.fit(users=df_int.user.unique(), items=df_int.repository.unique(), item_features=item_features)\n",
    "print(ds_item_features.interactions_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesito ahora armar una estructura donde para cada item, todas sus features:\n",
    "\n",
    "```\n",
    "[\"repo_1\", [\"python\", \"nlp\", etc...]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_flattened(item):\n",
    "    if type(item) in [list, tuple]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(collection):\n",
    "    flatted_collection = []\n",
    "    for item in collection:\n",
    "        if is_flattened(item):\n",
    "            flatted_collection += flatten(item)\n",
    "        else:\n",
    "            flatted_collection.append(item)\n",
    "    return(flatted_collection)\n",
    "\n",
    "# test\n",
    "#l = [1, 2, [3, 4], 5, [6, 7, 8], [9, [10, 11, 12], [13, 14, 15], 16], 17]\n",
    "#l = flatten(l)\n",
    "#l == [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17] # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifs = [] # la lista base que almacenara todos los items\n",
    "for idx, row in df_items.iterrows():\n",
    "    #print((row.id, (row.topics.split(\";\"), row.language.split(\";\"))))\n",
    "    topics_splitted = []\n",
    "    if row.topics is not None:\n",
    "        topics_splitted = row.topics.split(\";\")\n",
    "    \n",
    "    language_splitted = []\n",
    "    if row.language is not None:\n",
    "        language_splitted = row.language.split(\";\")\n",
    "    item_f = (\n",
    "        row.id,\n",
    "        tuple(\n",
    "            flatten(\n",
    "                (topics_splitted,\n",
    "                 language_splitted,\n",
    "                 row.forks,\n",
    "                 row.stars,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    ifs.append(item_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<298x1948 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 4720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features = ds_item_features.build_item_features(ifs)\n",
    "item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construyo las interacciones\n",
    "(lfm_interactions_ifs, lfm_weights_ifs) = ds_item_features.build_interactions(df_int[[\"user\", \"repository\"]].itertuples(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_items[[\"id\", \"forks\", \"stars\", \"watchers\", \"issues\", \"subscribers\"]]\n",
    "df_items_lfm = build_dummies(df_items, \"language\", remove_original_column=True)\n",
    "df_items_lfm = build_dummies(df_items_lfm, \"topics\", remove_original_column=True)\n",
    "\n",
    "df_items_lfm = df_items_lfm.drop(columns=[\"about\", \"es_fork\", \"archived\"], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f9408500250>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lfm_train_ifs, lfm_test_ifs) = lfm.cross_validation.random_train_test_split(lfm_interactions_ifs, test_percentage=0.2, random_state=42)\n",
    "\n",
    "model_ifs = lfm.LightFM(no_components=10, k=5, n=10, learning_schedule='adagrad', loss='logistic', learning_rate=0.05, rho=0.95, epsilon=1e-06, item_alpha=0.0, user_alpha=0.0, max_sampled=10, random_state=None)\n",
    "model_ifs.fit(lfm_train_ifs,\n",
    "          #sample_weight=lfm_train_w #no aplica porque son likes\n",
    "          item_features=item_features,\n",
    "          epochs=64,\n",
    "          num_threads=8,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005391493\n",
      "0.0034220533\n"
     ]
    }
   ],
   "source": [
    "train_precision_ifs = lfm.evaluation.precision_at_k(model_ifs, lfm_train_ifs, item_features=item_features, k=10, preserve_rows=False, num_threads=8, check_intersections=True)\n",
    "test_precision_ifs = lfm.evaluation.precision_at_k(model_ifs, lfm_test_ifs, item_features=item_features, k=10, preserve_rows=False, num_threads=8, check_intersections=True)\n",
    "\n",
    "print(train_precision_ifs.mean())\n",
    "print(test_precision_ifs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de los modelos\n",
    "\n",
    "NDCG\n",
    "\n",
    "https://gist.github.com/jbochi/2e8ddcc5939e70e5368326aa034a144e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
